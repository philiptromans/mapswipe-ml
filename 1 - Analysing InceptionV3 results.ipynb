{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "layout: post\n",
    "title: Finetuning InceptionV3 for MapSwipe\n",
    "math: true\n",
    "date: 2018-01-09\n",
    "tags: missing-maps mapswipe ml\n",
    "src: https://github.com/philiptromans/mapswipe-ml/blob/master/1%20-%20Analysing%20InceptionV3%20results.ipynb\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much of the world isn't mapped. This seems odd at first, but it basically comes down to a question of cash, and a large chunk of the world doesn't have enough of it. Maps are important, and when big charities like the [Red Cross](https://www.icrc.org/), or [M&eacute;decins Sans Fronti&egrave;res](https://www.msf.org.uk) try to respond to crises, or run public health projects, the lack of mapping is a serious problem. This is why the [Missing Maps](http://www.missingmaps.org/) project came into existence. It's a volunteer project with the goal of putting the world's most vulnerable people on the map. In more concrete terms, volunteers spend time pouring over satellite imagery, tracing over things like roads and buildings (you can learn more [here](http://www.missingmaps.org/)), and this data's then available for anyone to use. This is a time-consuming process, and much of the world is pretty empty (you don't see many buildings in the rainforest, or the desert). The [MapSwipe](https://mapswipe.org/) app was created to help accelerate the mapping process, by pre-filtering the tiles. MapSwipe users scroll through bits of satellite imagery (in a  mobile app), and identify images with buildings and other features in (depending on the project). Once this data has been gathered it means that the mapping volunteers can maximize their productivity, by going straight to the tiles that need mapping and not waste their time pouring over large expanses of forest (say).\n",
    "\n",
    "When I first heard about this, I thought that it sounded like a machine learning problem. I'm not necessarily looking to automate MapSwipe - that might well be quite hard. A good chunk of the tiles in a MapSwipe problem are pretty easy to identify though, and it makes sense for humans to be principally involved in the more difficult ones. A good ML solution could also be used to partially verify the output of the human mappers - it might help notice missing buildings or roads for example. It's also a useful exercise in trying to solve the eventual MissingMaps problem - generating maps straight from the raw satellite imagery. Before we continue, we need to properly define the MapSwipe problem. MapSwipe is a classification problem - users classify a single tile of satellite imagery as either:\n",
    "\n",
    "| Example       | Class         \n",
    "| :-------------: |:-------------:|\n",
    "| ![Example Bad Imagery](bad_imagery.jpg) | **Bad Imagery** means that something on the ground can't be seen. This is often because of cloud cover obstructing the satellite's view, or sometimes because something seems to be broken with the satellite. |\n",
    "| ![Example Built](built.jpg) | **Built** imagery means that there are buildings in view. |\n",
    "| ![Example Empty](empty.jpg) | **Empty** imagery contains no buildings. |\n",
    "\n",
    "To make life a little easier, I chose to only consider the projects that are solely focussed on finding buildings (roads can be tackled another day).\n",
    "\n",
    "For my first attempt at using machine learning to solve the MapSwipe problem, I followed the approach laid out in the first few lectures of the [fast.ai](http://fast.ai) course. Basically, you take a neural network that has already been trained to solve the [ImageNet](https://en.wikipedia.org/wiki/ImageNet) problem, and adapt it for your own computer vision problem. The next section outlines exactly what I did, but feel free to skip to the results section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## My first experiment\n",
    "\n",
    "All scripts used are present in my [mapswipe-ml](https://github.com/philiptromans/mapswipe-ml) repository **(need to tag this once I'm sure that everything's committed)**.\n",
    "\n",
    "I started by generating a dataset. There's a fuller explanation of the ```generate_dataset.py``` script in the repository, but essentially it downloads as many examples as possible of the three categories: bad imagery, built and empty, whilst keeping the sizes of the three groups the same. The projects that I selected were all that had their ```lookFor``` property set to ```buildings only```. (It now transpires that there's a similar category, which some of the newer projects fall into, which is just ```buildings``` - these were not included). This is approximately 1.4 million images. They are split 80-10-10 into a training set, a validation set and a test set.\n",
    "\n",
    "```\n",
    "python3 generate_dataset.py 124 303 407 692 1166 1333 1440 1599 1788 1901 2020 2158 2293 2473 2644 2671 2809 2978 3121 3310 3440 3610 3764 3906 4103 4242 4355 4543 4743 4877 5061 5169 5291 5368 5519 5688 5870 5990 6027 6175 6310 6498 6628 6637 6646 6794 6807 6918 6930 7049 7056 7064 7108 7124 7125 7260 7280 7281 7605 7738 7871 8059 8324 -k <bing maps api key> -o experiment_1/all_projects_dataset --inner-test-dir-for-keras\n",
    "```\n",
    "\n",
    "To actually create the model, I used [Keras](https://keras.io) to fine-tune Google's InceptionV3 model. This means removing its top layer of output neurons, and replacing them with three fully connected output neurons (one for each class), with a Softmax output (see the script for exact details - I've omitted a couple of layers for brevity). During the training process, only the top (newly added) layers are trained.\n",
    "\n",
    "```\n",
    "python3 train.py --dataset-dir experiment_1/all_projects_dataset --output-dir experiment_1/inception_v3_fine_tuned --fine-tune --num-epochs 1\n",
    "```\n",
    "\n",
    "After one epoch of training, you get a model with a validation accuracy of approximately 54%. With extra epochs of fine tuning this increases slightly, but I didn't feel that it was particularly worth doing. Instead, I thought about the ImageNet problem. ImageNet is primarily concerned with identifying the one object that dominates the foreground of any particular photo. MapSwipe is fundamentally different, in that it's more about considering the whole image, and any piece of the image may either have something obscuring it (in the case of bad imagery), or a building, which changes the entire image's classification. The objects being identified are less complex than ImageNet (where you need to be able to, say, differentiate between a cat's face and a dog's), but the whole image is more important in the MapSwipe problem (whereas ImageNet has a better separation of foreground and background). Considering this hypothesis, I decided to train all layers of ImageNet for several epochs:\n",
    "\n",
    "```\n",
    "python3 train.py --dataset-dir experiment_1/all_projects_dataset --output-dir experiment_1/inception_v3_all_layers --num-epochs 10 --start_model experiment_1/inception_v3_fine_tuned/model.01-0.906-0.539.hdf5\n",
    "```\n",
    "\n",
    "I let it train for 9 epochs before stopping it (I was using an Amazon AWS P3.2xlarge instance, which isn't cheap) to see how it was progressing. The final trained model had a validation accuracy of 65%. The accuracy was always increasing, but the rate of increase had slowed significantly. I suspect that there's more improvement to be made by training for longer, but I wanted to start analysing the results.\n",
    "\n",
    "To classify the test set:\n",
    "```\n",
    "python3 test.py --dataset-dir experiment_1/all_projects_dataset/test/ -m experiment_1/inception_v3_all_layers/model.01-0.906-0.539.hdf5.09-0.737-0.649.hdf5 -o experiment_1/inception_v3_all_layers.results\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "The first question on your mind is probably, \"How accurate was it?\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6432250733187717"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mapswipe_analysis import *\n",
    "\n",
    "all_projects_solution = Solution(\n",
    "    ground_truth_solutions_file_to_map('../experiment_1/all_projects_dataset/test/solutions.csv'),\n",
    "    predictions_file_to_map('../experiment_1/inception_v3_all_layers.results')\n",
    ")\n",
    "all_projects_solution.accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we're about 64% accurate. This means that 64% of the time, we select the right class for the tile (bad imagery, built, or empty). If we guessed at random, we'd expect to be 33% accurate (there are three classes, so we have a one in three chance of being correct). Let's break down that accuracy in to a per-category accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad_imagery</th>\n",
       "      <th>built</th>\n",
       "      <th>empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Test dataset</th>\n",
       "      <td>0.552432</td>\n",
       "      <td>0.667687</td>\n",
       "      <td>0.709556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "category_accuracies_df = pd.DataFrame(all_projects_solution.category_accuracies, index=class_names, columns=['Test dataset'])\n",
    "display(HTML(category_accuracies_df.transpose().to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems almost suspicious that our bad image detection accuracy is so much lower than the other categories. Let's break down this accuracy data further into a confusion matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad_imagery</th>\n",
       "      <th>built</th>\n",
       "      <th>empty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>bad_imagery</th>\n",
       "      <td>27062</td>\n",
       "      <td>3441</td>\n",
       "      <td>18484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>built</th>\n",
       "      <td>4061</td>\n",
       "      <td>32708</td>\n",
       "      <td>12218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>empty</th>\n",
       "      <td>9955</td>\n",
       "      <td>4273</td>\n",
       "      <td>34759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix_df = pd.DataFrame(all_projects_solution.confusion_matrix, index=class_names, columns=class_names)\n",
    "display(HTML(conf_matrix_df.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows correspond to what our model predicted, and the columns correspond to the official solution. If our model was perfect, we'd expect to have non-zero entries on the main diagonal (top left to bottom right), and zeroes everywhere else. The biggest non-zero entry corresponds to examples that officially (according to the MapSwipe data) are bad imagery, but our model has classified as empty. Let's take a look at the examples where we were most confident that the imagery was empty, but was actually bad (according to the official solution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=13.111580118251638~102.777099609375&lvl=18&style=a\" target=\"_blank\">132212212003211000</a><br>Officially: bad_imagery<br>Predicted class: empty<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/064/132212212003211000.jpg\"/><br>PV:[0.01397401 0.02337974 0.96264625]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=12.972442010578362~102.75100708007812&lvl=18&style=a\" target=\"_blank\">132212212023002101</a><br>Officially: bad_imagery<br>Predicted class: empty<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/017/132212212023002101.jpg\"/><br>PV:[0.02471545 0.0167773  0.95850724]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=13.890077963248643~102.76473999023438&lvl=18&style=a\" target=\"_blank\">132212210001023113</a><br>Officially: bad_imagery<br>Predicted class: empty<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/087/132212210001023113.jpg\"/><br>PV:[0.02505477 0.02580438 0.9491408 ]</td></tr><tr><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=15.02570678068517~105.79421997070312&lvl=18&style=a\" target=\"_blank\">132212130033101123</a><br>Officially: bad_imagery<br>Predicted class: empty<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/091/132212130033101123.jpg\"/><br>PV:[0.03569183 0.01793411 0.9463741 ]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=14.487871434931563~105.51132202148438&lvl=18&style=a\" target=\"_blank\">132212132002033111</a><br>Officially: bad_imagery<br>Predicted class: empty<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/085/132212132002033111.jpg\"/><br>PV:[0.05563853 0.01403912 0.93032235]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=15.75789280617633~106.43966674804688&lvl=18&style=a\" target=\"_blank\">132212113031022031</a><br>Officially: bad_imagery<br>Predicted class: empty<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/013/132212113031022031.jpg\"/><br>PV:[0.0451606  0.02489267 0.9299468 ]</td></tr><tr><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=14.490530661410489~105.4522705078125&lvl=18&style=a\" target=\"_blank\">132212123113130320</a><br>Officially: bad_imagery<br>Predicted class: empty<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/056/132212123113130320.jpg\"/><br>PV:[0.06579539 0.00917824 0.92502636]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=14.171197284392946~105.94528198242188&lvl=18&style=a\" target=\"_blank\">132212132303011231</a><br>Officially: bad_imagery<br>Predicted class: empty<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/109/132212132303011231.jpg\"/><br>PV:[0.07165854 0.00919708 0.9191443 ]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=15.884734325453593~106.50283813476562&lvl=18&style=a\" target=\"_blank\">132212113011332021</a><br>Officially: bad_imagery<br>Predicted class: empty<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/009/132212113011332021.jpg\"/><br>PV:[0.06143104 0.01993423 0.91863465]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quadkeys = [x[0] for x in all_projects_solution.classified_as(predicted_class='empty', solution_class='bad_imagery')[0:9]]\n",
    "tableau(quadkeys, all_projects_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(note that the prediction vectors have the form $(\\mathbb{P}(\\text{bad_imagery}), \\mathbb{P}(\\text{built}), \\mathbb{P}(\\text{empty}))$, where $\\mathbb{P}$ denotes a probability)\n",
    "\n",
    "As you can see, all of these images seem perfectly fine, and all in fact show land with no buildings. Now, we've only looked at the 9 that the model's most confident about, but I've skimmed through a large number of them (not included here for brevity) and whilst the occasional one has a small amount of cloud cover, the vast majority are absolutely fine.\n",
    "\n",
    "I'm not sure why this is happening, but I have a few hypotheses:\n",
    "* A significant number of users may be mistaken about the definition of bad imagery, or unsure about what to do for empty tiles (and are triple tapping to feed back that the images are empty, when they should just be ignoring them).\n",
    "* Bing may have updated the imagery since the feedback was gained from the users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's also interesting to review some other scenarios. Here are some images that the solution defines as empty, but the model believes that they contain buildings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table><tr><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=14.277692206432462~-90.56716918945312&lvl=18&style=a\" target=\"_blank\">023313133023320231</a><br>Officially: empty<br>Predicted class: built<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/045/023313133023320231.jpg\"/><br>PV:[3.4844992e-03 9.9635458e-01 1.6092640e-04]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=-1.029912794048144~35.5078125&lvl=18&style=a\" target=\"_blank\">300110012122202220</a><br>Officially: empty<br>Predicted class: built<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/040/300110012122202220.jpg\"/><br>PV:[0.00453361 0.9944021  0.00106429]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=14.850558661795276~106.80770874023438&lvl=18&style=a\" target=\"_blank\">132212131313001333</a><br>Officially: empty<br>Predicted class: built<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/127/132212131313001333.jpg\"/><br>PV:[0.00127954 0.99339586 0.00532465]</td></tr><tr><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=14.705821604736087~106.8585205078125&lvl=18&style=a\" target=\"_blank\">132212131331330300</a><br>Officially: empty<br>Predicted class: built<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/048/132212131331330300.jpg\"/><br>PV:[0.00491786 0.9876587  0.00742349]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=-24.952444759841555~44.723968505859375&lvl=18&style=a\" target=\"_blank\">300311311302130313</a><br>Officially: empty<br>Predicted class: built<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/055/300311311302130313.jpg\"/><br>PV:[0.010339   0.9842988  0.00536216]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=8.936626875428615~27.21588134765625&lvl=18&style=a\" target=\"_blank\">122320132103323030</a><br>Officially: empty<br>Predicted class: built<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/076/122320132103323030.jpg\"/><br>PV:[0.01284369 0.98264277 0.00451359]</td></tr><tr><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=8.608178607442497~27.384796142578125&lvl=18&style=a\" target=\"_blank\">122320132313302301</a><br>Officially: empty<br>Predicted class: built<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/049/122320132313302301.jpg\"/><br>PV:[0.01074562 0.9814532  0.00780118]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=9.012589671033297~27.802276611328125&lvl=18&style=a\" target=\"_blank\">122320133102010121</a><br>Officially: empty<br>Predicted class: built<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/025/122320133102010121.jpg\"/><br>PV:[0.01149258 0.98020375 0.00830375]</td><td align=\"center\" style=\"text-align: center\">Quadkey: <a href=\"http://bing.com/maps/default.aspx?cp=9.051921278888528~27.73773193359375&lvl=18&style=a\" target=\"_blank\">122320133011300312</a><br>Officially: empty<br>Predicted class: built<br><img align=\"center\" src=\"mapswipe_working_dir/tiles/054/122320133011300312.jpg\"/><br>PV:[0.01287544 0.9798688  0.00725573]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "quadkeys = [x[0] for x in all_projects_solution.classified_as(predicted_class='built', solution_class='empty')[0:9]]\n",
    "tableau(quadkeys, all_projects_solution)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, it's not quite as open-and-shut as the previous set of examples, but it still helps build confidence in the model, and support the hypothesis that the MapSwipe data is far from accurate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Individual Project Accuracy\n",
    "\n",
    "Everything we've done so far has considered one giant dataset, composed of a large number of projects (where each project corresponds to relatively small geographic area). It's interesting to see if the model's accuracy varies between the individual projects. To do this, I generated individual datasets for each project (using a similar workflow to that described previously), and then used the same model as before to grade each individual project's test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"f3f88c38-08fe-4fe0-8da6-ad1850dbac50\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id !== undefined) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var element_id = msg.content.text.trim();\n",
       "            Bokeh.index[element_id].model.document.clear();\n",
       "            delete Bokeh.index[element_id];\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[0].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[0].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[0]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"f3f88c38-08fe-4fe0-8da6-ad1850dbac50\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n",
       "    }\n",
       "    finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.info(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(js_urls, callback) {\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = js_urls.length;\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var s = document.createElement('script');\n",
       "      s.src = url;\n",
       "      s.async = false;\n",
       "      s.onreadystatechange = s.onload = function() {\n",
       "        root._bokeh_is_loading--;\n",
       "        if (root._bokeh_is_loading === 0) {\n",
       "          console.log(\"Bokeh: all BokehJS libraries loaded\");\n",
       "          run_callbacks()\n",
       "        }\n",
       "      };\n",
       "      s.onerror = function() {\n",
       "        console.warn(\"failed to load library \" + url);\n",
       "      };\n",
       "      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "    }\n",
       "  };var element = document.getElementById(\"f3f88c38-08fe-4fe0-8da6-ad1850dbac50\");\n",
       "  if (element == null) {\n",
       "    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'f3f88c38-08fe-4fe0-8da6-ad1850dbac50' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n",
       "      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"f3f88c38-08fe-4fe0-8da6-ad1850dbac50\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(js_urls, function() {\n",
       "      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof (root._bokeh_onload_callbacks) === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"f3f88c38-08fe-4fe0-8da6-ad1850dbac50\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) { callback() });\n    }\n    finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.info(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(js_urls, callback) {\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.log(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.log(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = js_urls.length;\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var s = document.createElement('script');\n      s.src = url;\n      s.async = false;\n      s.onreadystatechange = s.onload = function() {\n        root._bokeh_is_loading--;\n        if (root._bokeh_is_loading === 0) {\n          console.log(\"Bokeh: all BokehJS libraries loaded\");\n          run_callbacks()\n        }\n      };\n      s.onerror = function() {\n        console.warn(\"failed to load library \" + url);\n      };\n      console.log(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.getElementsByTagName(\"head\")[0].appendChild(s);\n    }\n  };var element = document.getElementById(\"f3f88c38-08fe-4fe0-8da6-ad1850dbac50\");\n  if (element == null) {\n    console.log(\"Bokeh: ERROR: autoload.js configured with elementid 'f3f88c38-08fe-4fe0-8da6-ad1850dbac50' but no matching script tag was found. \")\n    return false;\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-0.12.13.min.js\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-widgets-0.12.13.min.css\");\n      console.log(\"Bokeh: injecting CSS: https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n      Bokeh.embed.inject_css(\"https://cdn.pydata.org/bokeh/release/bokeh-tables-0.12.13.min.css\");\n    }\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"f3f88c38-08fe-4fe0-8da6-ad1850dbac50\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.log(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(js_urls, function() {\n      console.log(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<div class=\"bk-root\">\n",
       "    <div class=\"bk-plotdiv\" id=\"f1b04ab3-5c9b-4909-a7c8-da0944335d64\"></div>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "(function(root) {\n",
       "  function embed_document(root) {\n",
       "    \n",
       "  var docs_json = {\"91030c53-91f5-4ea7-9d3d-0164c661ba9f\":{\"roots\":{\"references\":[{\"attributes\":{\"callback\":null},\"id\":\"92e34a28-27f2-40af-8fd2-d6ae22470a59\",\"type\":\"DataRange1d\"},{\"attributes\":{\"active_drag\":\"auto\",\"active_inspect\":\"auto\",\"active_scroll\":\"auto\",\"active_tap\":\"auto\",\"tools\":[{\"id\":\"1571c1a2-7905-405a-9a43-65802dafd65c\",\"type\":\"HoverTool\"}]},\"id\":\"993bb32a-d7df-47c0-8ed4-4c2aa680f2b8\",\"type\":\"Toolbar\"},{\"attributes\":{\"callback\":null},\"id\":\"7814cd14-1330-441a-a36c-889074666f71\",\"type\":\"DataRange1d\"},{\"attributes\":{},\"id\":\"b01fbd84-b746-4a17-8849-b80a08ebf02e\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{},\"id\":\"7f0924e1-7f46-4fa4-bd36-afb69b92fde5\",\"type\":\"LinearScale\"},{\"attributes\":{\"data_source\":{\"id\":\"1650c1f7-993f-48d4-af77-ca9858301755\",\"type\":\"ColumnDataSource\"},\"glyph\":{\"id\":\"ceef80d4-9009-4f59-96e3-89d6a678a220\",\"type\":\"Circle\"},\"hover_glyph\":null,\"muted_glyph\":null,\"nonselection_glyph\":{\"id\":\"14ba7200-15a3-4b9b-94ee-67390b1388b3\",\"type\":\"Circle\"},\"selection_glyph\":null,\"view\":{\"id\":\"dd6e4a55-b91c-4ad0-8aba-fa4b2ec728a6\",\"type\":\"CDSView\"}},\"id\":\"dfc8da7d-1c85-4461-a815-4469328db040\",\"type\":\"GlyphRenderer\"},{\"attributes\":{},\"id\":\"6b06e08f-a5bf-48e8-bdc7-63feaed19c1a\",\"type\":\"LinearScale\"},{\"attributes\":{\"formatter\":{\"id\":\"a6ba8181-9747-4a4f-8ed8-09da9b5e35ca\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"18b2bf94-0495-4e00-a7c9-112d54a0d65d\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b68ddf38-bfa7-43cf-9979-3580bb375eb2\",\"type\":\"BasicTicker\"}},\"id\":\"2c64a368-d0c5-40d3-b833-16882ef100ae\",\"type\":\"LinearAxis\"},{\"attributes\":{},\"id\":\"b68ddf38-bfa7-43cf-9979-3580bb375eb2\",\"type\":\"BasicTicker\"},{\"attributes\":{\"callback\":null,\"tooltips\":[[\"Project ID\",\"@x\"],[\"Accuracy\",\"@y%\"],[\"Name\",\"@names\"],[\"Tile count\",\"@tile_counts\"]]},\"id\":\"1571c1a2-7905-405a-9a43-65802dafd65c\",\"type\":\"HoverTool\"},{\"attributes\":{\"callback\":null,\"column_names\":[\"x\",\"y\",\"names\",\"tile_counts\"],\"data\":{\"names\":[\"MapSwipe Madagascar\",\"MapSwipe Madagascar 2\",\"MapSwipe Madagascar 3\",\"MapSwipe Guatemala\",\"MapSwipe Madagascar 4\",\"MapSwipe Madagascar 5\",\"MapSwipe Madagascar 6\",\"Botswana Malaria Control 1\",\"Botswana Malaria Control 2\",\"Botswana Malaria Control 3\",\"Missing Maps Malawi 2\",\"MapSwipe Madagascar 7\",\"Missing Maps Malawi 3\",\"Map Chad for MSF (part 1)\",\"Map South Sudan for MSF (part 1)\",\"Map Maswa, Tanzania\",\"Botswana Malaria Control 4\",\"Map South Sudan for MSF (part 2)\",\"Map South Sudan for MSF (part 3)\",\"MapSwipe Madagascar 8\",\"Botswana Malaria Control 5\",\"MapSwipe Madagascar 9\",\"Drought in Mara, Kenya\",\"Drought in Mara, Kenya (2/2)\",\"MapSwipe Madagascar 10\",\"MapSwipe Nigeria for MSF 1\",\"Botswana Malaria Control 6\",\"Map Sierra Leone for MSF\",\"MapSwipe Nigeria for MSF 2\",\"MapSwipe Nigeria for MSF 3\",\"MapSwipe Nigeria for MSF 4\",\"Map Sierra Leone for MSF 2\",\"Map Sierra Leone for MSF 4\",\"Map Sierra Leone for MSF 3\",\"Disease elimination on Bijagos islands 1\",\"Disease elimination on Bijagos islands 2\",\"Disease elimination on Bijagos islands 3\",\"Disease elimination on Bijagos islands 5\",\"Disease elimination on Bijagos islands 6\",\"Botswana Malaria Control 7\",\"MapSwipe Nigeria for MSF 5\",\"Eliminate Malaria: Cambodia\",\"Eliminate Malaria: Cambodia 2\",\"Eliminate Malaria: Cambodia 3\",\"Eliminate Malaria: Cambodia 4\",\"Eliminate Malaria: Laos 2\",\"Eliminate Malaria: Laos\",\"Eliminate Malaria: Laos 6\",\"Eliminate Malaria: Laos 3\",\"Eliminate Malaria: Laos 7\",\"Prevent FGM: Singida, Tanzania 2\",\"Eliminate Malaria: Laos 4\",\"Eliminate Malaria: Laos 8\",\"Eliminate Malaria: Laos 5\",\"MapSwipe Nigeria for MSF 7\",\"MapSwipe Nigeria for MSF 8\",\"MapSwipe Nigeria for MSF 6\",\"MapSwipe Madagascar 11\",\"MapSwipe Madagascar 12\",\"Prevent FGM: Sawida, Tanzania\",\"Prevent FGM: Kulimi, Tanzania\",\"Eliminate Malaria: Angola 1\"],\"tile_counts\":[3999,4557,2868,6372,3840,3168,5361,894,1194,2697,111,3342,744,3990,5379,360,1896,4194,2583,2010,1494,2205,573,3102,6171,7428,1899,717,6444,3762,897,1077,174,366,120,3,21,78,6,1065,1827,690,4236,1524,945,1329,6273,2124,2649,78,1209,3672,414,723,4884,2364,1776,2241,5778,312,75,5121],\"x\":[\"124\",\"303\",\"407\",\"692\",\"1166\",\"1333\",\"1440\",\"1599\",\"1788\",\"1901\",\"2020\",\"2158\",\"2293\",\"2473\",\"2644\",\"2671\",\"2809\",\"2978\",\"3121\",\"3310\",\"3440\",\"3610\",\"3764\",\"3906\",\"4103\",\"4242\",\"4355\",\"4543\",\"4743\",\"4877\",\"5061\",\"5169\",\"5291\",\"5368\",\"5519\",\"5688\",\"5870\",\"5990\",\"6027\",\"6175\",\"6310\",\"6498\",\"6628\",\"6637\",\"6646\",\"6794\",\"6807\",\"6918\",\"6930\",\"7049\",\"7056\",\"7064\",\"7108\",\"7125\",\"7260\",\"7280\",\"7281\",\"7605\",\"7738\",\"7871\",\"8059\",\"8324\"],\"y\":[58.81470367591898,59.73228000877771,54.32357043235704,67.78091650973008,65.52083333333333,62.34217171717172,61.779518746502525,46.97986577181208,56.700167504187604,52.206154987022614,61.26126126126127,61.96888090963495,65.32258064516128,61.67919799498747,61.98178100018591,64.99999999999999,58.64978902953587,64.75917978063902,65.27293844367014,54.179104477611936,49.79919678714859,55.69160997732426,54.62478184991274,66.98903932946486,63.749797439637014,65.14539579967689,40.7056345444971,58.995815899581594,65.84419615145872,64.11483253588517,61.53846153846154,61.745589600742804,51.724137931034484,65.02732240437159,54.166666666666664,66.66666666666666,61.904761904761905,53.84615384615385,33.33333333333333,53.14553990610329,65.79091406677614,72.46376811594203,85.93012275731823,78.87139107611549,80.95238095238095,70.05267118133935,83.66013071895425,78.57815442561206,71.27217818044545,80.76923076923079,74.27626137303557,85.48474945533769,83.57487922705315,84.23236514522821,68.85749385749385,57.275803722504236,56.981981981981974,64.4355198572066,64.01869158878505,63.141025641025635,52.0,43.975785979300916]}},\"id\":\"1650c1f7-993f-48d4-af77-ca9858301755\",\"type\":\"ColumnDataSource\"},{\"attributes\":{\"plot\":{\"id\":\"18b2bf94-0495-4e00-a7c9-112d54a0d65d\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"b68ddf38-bfa7-43cf-9979-3580bb375eb2\",\"type\":\"BasicTicker\"}},\"id\":\"7dcd330d-921b-4751-9056-77067fecbcc3\",\"type\":\"Grid\"},{\"attributes\":{\"formatter\":{\"id\":\"b01fbd84-b746-4a17-8849-b80a08ebf02e\",\"type\":\"BasicTickFormatter\"},\"plot\":{\"id\":\"18b2bf94-0495-4e00-a7c9-112d54a0d65d\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a244b401-5ee9-4ba0-b2c9-bce63052ee12\",\"type\":\"BasicTicker\"}},\"id\":\"88a168c3-24f7-4506-952c-dd6f6812827c\",\"type\":\"LinearAxis\"},{\"attributes\":{\"source\":{\"id\":\"1650c1f7-993f-48d4-af77-ca9858301755\",\"type\":\"ColumnDataSource\"}},\"id\":\"dd6e4a55-b91c-4ad0-8aba-fa4b2ec728a6\",\"type\":\"CDSView\"},{\"attributes\":{},\"id\":\"a244b401-5ee9-4ba0-b2c9-bce63052ee12\",\"type\":\"BasicTicker\"},{\"attributes\":{\"dimension\":1,\"plot\":{\"id\":\"18b2bf94-0495-4e00-a7c9-112d54a0d65d\",\"subtype\":\"Figure\",\"type\":\"Plot\"},\"ticker\":{\"id\":\"a244b401-5ee9-4ba0-b2c9-bce63052ee12\",\"type\":\"BasicTicker\"}},\"id\":\"757df94d-41b1-4c6b-b0d4-662a309919a6\",\"type\":\"Grid\"},{\"attributes\":{},\"id\":\"a6ba8181-9747-4a4f-8ed8-09da9b5e35ca\",\"type\":\"BasicTickFormatter\"},{\"attributes\":{\"below\":[{\"id\":\"2c64a368-d0c5-40d3-b833-16882ef100ae\",\"type\":\"LinearAxis\"}],\"left\":[{\"id\":\"88a168c3-24f7-4506-952c-dd6f6812827c\",\"type\":\"LinearAxis\"}],\"plot_width\":800,\"renderers\":[{\"id\":\"2c64a368-d0c5-40d3-b833-16882ef100ae\",\"type\":\"LinearAxis\"},{\"id\":\"7dcd330d-921b-4751-9056-77067fecbcc3\",\"type\":\"Grid\"},{\"id\":\"88a168c3-24f7-4506-952c-dd6f6812827c\",\"type\":\"LinearAxis\"},{\"id\":\"757df94d-41b1-4c6b-b0d4-662a309919a6\",\"type\":\"Grid\"},{\"id\":\"dfc8da7d-1c85-4461-a815-4469328db040\",\"type\":\"GlyphRenderer\"}],\"title\":{\"id\":\"a578e890-8702-4c14-a336-b1995467e65f\",\"type\":\"Title\"},\"toolbar\":{\"id\":\"993bb32a-d7df-47c0-8ed4-4c2aa680f2b8\",\"type\":\"Toolbar\"},\"x_range\":{\"id\":\"92e34a28-27f2-40af-8fd2-d6ae22470a59\",\"type\":\"DataRange1d\"},\"x_scale\":{\"id\":\"7f0924e1-7f46-4fa4-bd36-afb69b92fde5\",\"type\":\"LinearScale\"},\"y_range\":{\"id\":\"7814cd14-1330-441a-a36c-889074666f71\",\"type\":\"DataRange1d\"},\"y_scale\":{\"id\":\"6b06e08f-a5bf-48e8-bdc7-63feaed19c1a\",\"type\":\"LinearScale\"}},\"id\":\"18b2bf94-0495-4e00-a7c9-112d54a0d65d\",\"subtype\":\"Figure\",\"type\":\"Plot\"},{\"attributes\":{\"fill_color\":{\"value\":\"#1f77b4\"},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"ceef80d4-9009-4f59-96e3-89d6a678a220\",\"type\":\"Circle\"},{\"attributes\":{\"fill_alpha\":{\"value\":0.1},\"fill_color\":{\"value\":\"#1f77b4\"},\"line_alpha\":{\"value\":0.1},\"line_color\":{\"value\":\"#1f77b4\"},\"size\":{\"units\":\"screen\",\"value\":10},\"x\":{\"field\":\"x\"},\"y\":{\"field\":\"y\"}},\"id\":\"14ba7200-15a3-4b9b-94ee-67390b1388b3\",\"type\":\"Circle\"},{\"attributes\":{\"plot\":null,\"text\":\"Test accuracy for each MapSwipe project\"},\"id\":\"a578e890-8702-4c14-a336-b1995467e65f\",\"type\":\"Title\"}],\"root_ids\":[\"18b2bf94-0495-4e00-a7c9-112d54a0d65d\"]},\"title\":\"Bokeh Application\",\"version\":\"0.12.13\"}};\n",
       "  var render_items = [{\"docid\":\"91030c53-91f5-4ea7-9d3d-0164c661ba9f\",\"elementid\":\"f1b04ab3-5c9b-4909-a7c8-da0944335d64\",\"modelid\":\"18b2bf94-0495-4e00-a7c9-112d54a0d65d\"}];\n",
       "  root.Bokeh.embed.embed_items_notebook(docs_json, render_items);\n",
       "\n",
       "  }\n",
       "  if (root.Bokeh !== undefined) {\n",
       "    embed_document(root);\n",
       "  } else {\n",
       "    var attempts = 0;\n",
       "    var timer = setInterval(function(root) {\n",
       "      if (root.Bokeh !== undefined) {\n",
       "        embed_document(root);\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "      attempts++;\n",
       "      if (attempts > 100) {\n",
       "        console.log(\"Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing\")\n",
       "        clearInterval(timer);\n",
       "      }\n",
       "    }, 10, root)\n",
       "  }\n",
       "})(window);"
      ],
      "application/vnd.bokehjs_exec.v0+json": ""
     },
     "metadata": {
      "application/vnd.bokehjs_exec.v0+json": {
       "id": "18b2bf94-0495-4e00-a7c9-112d54a0d65d"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from os.path import isdir, join\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "from bokeh.plotting import figure, ColumnDataSource\n",
    "from bokeh.models import HoverTool\n",
    "from bokeh.io import output_notebook, show\n",
    "\n",
    "with urllib.request.urlopen(\"http://api.mapswipe.org/projects.json\") as url:\n",
    "    projects = json.loads(url.read().decode())\n",
    "\n",
    "individual_projects_dir = '../individual_projects/'\n",
    "project_dirs = [d for d in os.listdir(individual_projects_dir) if isdir(join(individual_projects_dir, d))]\n",
    "project_dirs.sort(key=int)\n",
    "\n",
    "project_ids = []\n",
    "accuracies = []\n",
    "names = []\n",
    "tile_counts = []\n",
    "\n",
    "for project_id in project_dirs:\n",
    "    solutions_csv = join(individual_projects_dir, project_id, 'test', 'solutions.csv')\n",
    "    if (os.path.getsize(solutions_csv) > 0):\n",
    "        solution = Solution(\n",
    "            ground_truth_solutions_file_to_map(solutions_csv),\n",
    "            predictions_file_to_map(join(individual_projects_dir, project_id, 'initial_inception_v3_all_layers.out'))\n",
    "        )\n",
    "        project_ids.append(project_id)\n",
    "        accuracies.append(solution.accuracy * 100)\n",
    "        names.append(projects[project_id]['name'])\n",
    "        tile_counts.append(solution.tile_count)\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "source = ColumnDataSource(data=dict(\n",
    "    x=project_ids,\n",
    "    y=accuracies,\n",
    "    names=names,\n",
    "    tile_counts=tile_counts\n",
    "))\n",
    "\n",
    "hover = HoverTool(tooltips=[\n",
    "    (\"Project ID\", \"@x\"),\n",
    "    (\"Accuracy\", \"@y%\"),\n",
    "    (\"Name\", \"@names\"),\n",
    "    (\"Tile count\", \"@tile_counts\")\n",
    "])\n",
    "\n",
    "p = figure(plot_width=800, plot_height=600, tools=[hover],\n",
    "           title=\"Test accuracy for each MapSwipe project\")\n",
    "\n",
    "p.circle('x', 'y', size=10, source=source)\n",
    "\n",
    "show(p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this figure, we're graphing the project ID against the accuracy of the model. Project IDs are set at the time the project was created, and as time goes on newer projects get larger IDs. So, the x-axis represents the passage of time in an arbitrary *(unlikely to be anything like linear)* scale. It's interesting to note that there isn't a huge amount of variety in the individual project accuracies (project 6027 is tiny, so it's barely worth considering). The only real insight is that the model seems to be particularly effective in the Cambodia / Laos region (you can hover your mouse over a mark on the scatter plot to see some project details)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further work\n",
    "\n",
    "I think it's pretty clear from what we've seen that a significant problem facing MapSwipe is data quality. A machine learning model is only as good as the data that goes into it, and mislabelled data could create confounding results for researchers trying to solve the problem. There are two obvious ways to try to solve this problem:\n",
    "* To include a tile in the dataset, I required at least one vote for a particular category, and no votes for the others. I suspect that increasing the vote threshold would produce more accurate models. This will have the effect of lowering the number of tiles in the dataset though, which isn't ideal. The other problem with this is that it's not possible to do consistently - empty tiles aren't explicitly marked as empty by MapSwipe users, they're just not marked at all. It's difficult to tell whether or not an image has been seen multiple times (although you can estimate it according to how often its explicitly marked neighbours have been viewed - this leads to its own problems in terms of bias though).\n",
    "* We could request more votes from users for tiles that the model has confidently classified, but classified incorrectly according to the official MapSwipe data. This'll require engineering, and user's time, but I think it's the most promising solution. To get a high quality model, a large amount of high quality data will be needed.\n",
    "\n",
    "If we consider the engineering problem previously suggested, it provides an opportunity to consider a fundamentally different data model. I propose that the data model should consist of a set of tiles. For each tile, a number of questions can be asked. For instance, \"Does this tile contain any buildings?\". The answer to this question is yes, no or maybe. Multiple questions can be assigned to a tile, which allows a tile to simultaneously contain buildings and be bad imagery (if it's partially obscured by cloud), which can't happen in the current model (but will act to confound many simple ML models). It also allows tiles to be explicitly marked as empty by users, as opposed to just being skipped, and not having any data recorded. This is critically important for training ML models in future, as the empty tiles are just as important as the built ones, and we must have a large amount of confidence in the training dataset's annotations for both categories."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
